# -*- coding: utf-8 -*-
"""CreditCardFraudDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HlifLnkuCGilj2-I4iL-di36QnBB1DtF
"""

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

ccd=pd.read_csv('creditcard.csv')
ccd.head()

ccd.tail()

ccd.info()

#checking number of missing value i each column
ccd.isnull().sum()

#filling null values
ccd2 =ccd.fillna(value=0)
ccd2.isnull().sum()
#fill nul value with previous value
ccd3 = ccd.fillna(method='pad')

# Replace null values with the mean of each column
ccd5 = ccd.fillna(ccd.mean())

# Verify that there are no null values left
print(ccd5.isnull().sum())

#distribution og legit transaction and fraudulent transaction
ccd5['Class'].value_counts()
#this dataset is highly unbalance

#seprating the data for analysis
legit=ccd5[ccd5.Class==0]
fraud=ccd5[ccd5.Class==1]
print(legit.shape)
print(fraud.shape)

legit.Amount.describe()

fraud.Amount.describe()

fraud['Class'].value_counts()

#compare the values for both transation
ccd5.groupby('Class').mean()

#undersampling

legit_sample = legit.sample(n=245)

#concatenating two dataframes
newdata = pd.concat([legit_sample,fraud],axis=0)
newdata.head()

newdata.tail()

newdata['Class'].value_counts()

X= newdata.drop(columns='Class',axis=1)
y=newdata['Class']
print(X)

print(y)

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify =y,random_state=2)

model =  LogisticRegression()

model.fit(X_train,y_train)

model.predict(X_test)

pred = model.predict(X_test)
accuracy1=accuracy_score(pred,y_test)
print('accuracy score : ',accuracy1)

